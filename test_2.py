import torch
import transformers

from transformers import LlamaForCausalLM, LlamaTokenizer
print('!')

# model_dir = "./llama-2-7b-chat-hf"
# model = LlamaForCausalLM.from_pretrained(model_dir)

# tokenizer = LlamaTokenizer.from_pretrained(model_dir)